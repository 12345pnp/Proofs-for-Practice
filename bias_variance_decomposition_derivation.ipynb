{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "$$ x, y \\in \\mathbb{R}  $$\n",
        "\n",
        "$$ y = f(x) + \\epsilon$$\n",
        "\n",
        "$$  \\epsilon \\in \\mathcal{N}(0, \\sigma_\\epsilon^2) $$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "$$ \\mathcal{D} = \\{{(x_i, y_i)}\\}_{i=1}^{n}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "$$ \\mathbb{E}_{\\mathcal{D}, \\epsilon}[ (\\hat{f}_\\mathcal{D}(x) - y)^2 ] =  \\mathbb{E}_{\\mathcal{D}, \\epsilon}[ (\\hat{f}_\\mathcal{D}(x) - f(x) - \\epsilon)^2 ]$$\n",
        "\n",
        "\n",
        "Note: $ \\hat{f}_\\mathcal{D}(x) $, and $\\epsilon$  are independent, because while the former is trained on $n$ samples from the input space, and contains noise sampled from given distribition above, $\\epsilon$ in this equation represents noise during prediction (i.e. testing), not the noise that was present in the training set. $\\epsilon_{train}$ and $\\epsilon_{test}$ are iids. Assume all $\\epsilon$ in this derivation refers to $\\epsilon_{test}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "$$ (\\hat{f}_\\mathcal{D}(x) - f(x) - \\epsilon)^2 = \\left( \\hat{f}_\\mathcal{D}(x) - f(x)\\right)^2 + \\epsilon^2 + 2\\epsilon \\left( \\hat{f}_\\mathcal{D}(x) - f(x)\\right) $$\n",
        "\n",
        "\n",
        "$$  \\mathbb{E}_{\\mathcal{D}, \\epsilon}[ (\\hat{f}_\\mathcal{D}(x) - f(x) - \\epsilon)^2 ]  =  \\mathbb{E}_{\\mathcal{D}} \\left[ \\left( \\hat{f}_\\mathcal{D}(x) - f(x)\\right)^2 \\right] + \n",
        "\\mathbb{E}_\\epsilon[\\epsilon^2] + \n",
        "2 \\cancel{\\mathbb{E}_{\\mathcal{D}} \\left[ \n",
        "    \\left( \\hat{f}_\\mathcal{D}(x) - f(x)\\right) \n",
        "\\right] \\mathbb{E}_{\\epsilon} [\\epsilon]} $$\n",
        "\n",
        "\n",
        "$$ \\mathbb{E}_{\\epsilon} [\\epsilon] = 0  $$\n",
        "\n",
        "\n",
        "$$\\mathbb{E}_\\epsilon[\\epsilon^2] = \\sigma_\\epsilon^2 $$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "$$ \\mathbb{E}_{\\mathcal{D}, \\epsilon}[ (\\hat{f}_\\mathcal{D}(x) - y)^2 ] = \\mathbb{E}_{\\mathcal{D}} \\left[ \\left( \\hat{f}_\\mathcal{D}(x) - f(x)\\right)^2 \\right] +  \\sigma_\\epsilon^2 $$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "$$\\left( \\hat{f}_\\mathcal{D}(x) - f(x)\\right)^2 = \\left(\\hat{f}_\\mathcal{D}(x) -  \\mathbb{E}_{\\mathcal{D}}[ \\hat{f}_\\mathcal{D}(x)] +  \\mathbb{E}_{\\mathcal{D}}[ \\hat{f}_\\mathcal{D}(x)] - f(x)\\right)^2 $$\n",
        "\n",
        "$$ =  \\left(\\hat{f}_\\mathcal{D}(x) -  \\mathbb{E}_{\\mathcal{D}}[ \\hat{f}_\\mathcal{D}(x)]\\right)^2 +  \n",
        "\\left( \\mathbb{E}_{\\mathcal{D}}[ \\hat{f}_\\mathcal{D}(x)] - f(x) \\right)^2 +\n",
        "2  \\left(\\hat{f}_\\mathcal{D}(x) -  \\mathbb{E}_{\\mathcal{D}}[ \\hat{f}_\\mathcal{D}(x)]\\right)  \\left( \\mathbb{E}_{\\mathcal{D}}[ \\hat{f}_\\mathcal{D}(x)] - f(x) \\right)$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Note: $f(x)$ is independent of the dataset $\\mathcal{D}$. $  \\mathbb{E}_{\\mathcal{D}}[f(x)] = f(x)$\n",
        "\n",
        "$$ \\mathbb{E}_{\\mathcal{D}} \\left[ \\left(\\hat{f}_\\mathcal{D}(x) -  \\mathbb{E}_{\\mathcal{D}}[ \\hat{f}_\\mathcal{D}(x)]\\right)  \\left( \\mathbb{E}_{\\mathcal{D}}[ \\hat{f}_\\mathcal{D}(x)] - f(x) \\right) \\right]$$\n",
        "\n",
        "$$  = \\mathbb{E}_{\\mathcal{D}} \\left[  \\hat{f}_\\mathcal{D}(x) \\mathbb{E}_{\\mathcal{D}}[ \\hat{f}_\\mathcal{D}(x)] \\right] -\n",
        "\\mathbb{E}_{\\mathcal{D}} \\left[ \\hat{f}_\\mathcal{D}(x) f(x) \\right] -\n",
        "\\mathbb{E}_{\\mathcal{D}} \\left[ \\mathbb{E}_{\\mathcal{D}}[ \\hat{f}_\\mathcal{D}(x)]^2 \\right] + \n",
        "\\mathbb{E}_{\\mathcal{D}} \\left[ \\mathbb{E}_{\\mathcal{D}}[ \\hat{f}_\\mathcal{D}(x)]f(x) \\right]$$\n",
        "\n",
        "\n",
        "$$ = \\cancel{\\mathbb{E}_{\\mathcal{D}}[ \\hat{f}_\\mathcal{D}(x)]^2 } - \\cancel{\\mathbb{E}_{\\mathcal{D}}[ \\hat{f}_\\mathcal{D}(x)]f(x)} -  \\cancel{\\mathbb{E}_{\\mathcal{D}}[ \\hat{f}_\\mathcal{D}(x)]^2 } + \\cancel{\\mathbb{E}_{\\mathcal{D}}[ \\hat{f}_\\mathcal{D}(x)]f(x)} = 0$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Therefore:\n",
        "\n",
        "$$ \\mathbb{E}_{\\mathcal{D}, \\epsilon}[ (\\hat{f}_\\mathcal{D}(x) - y)^2 ] = \\mathbb{E}_{\\mathcal{D}} \\left[ \\left( \\hat{f}_\\mathcal{D}(x) - f(x)\\right)^2 \\right] +  \\sigma_\\epsilon^2 $$\n",
        "\n",
        "$$ =  \\mathbb{E}_{\\mathcal{D}} \\left[ \\left(\\hat{f}_\\mathcal{D}(x) -  \\mathbb{E}_{\\mathcal{D}}[ \\hat{f}_\\mathcal{D}(x)]\\right)^2  \\right] + \n",
        "\\left( \\mathbb{E}_{\\mathcal{D}}[ \\hat{f}_\\mathcal{D}(x)] - f(x) \\right)^2  \n",
        " +  \\sigma_\\epsilon^2 \n",
        "$$\n",
        "\n",
        "$$ =  \\mathrm{Var}_\\mathcal{D}[\\hat{f}_\\mathcal{D}(x)] +  \\left( \\mathrm{Bias}[\\hat{f}_\\mathcal{D}(x)] \\right)^2 + \\sigma_\\epsilon^2 $$"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "test_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
